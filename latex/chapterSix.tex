%
% $Id: chapterSix.tex
%

% A first, optional argument in [ ] is the title as displayed in the table of contents
% The second argument is the title as displayed here.  Use \\ as appropriate in
%   this title to get desired line breaks

%----------------------------------------------------------------------------------------
% Conclusion
%----------------------------------------------------------------------------------------
\chapter[Conclusion]{Conclusion}
\label{chp:conclusion}

This dissertation contributed to the computational physics and space weather communities in a number of ways.  New benchmarks for ideal MHD code validation were provided in Section~\ref{sec:riemann_mhd}.  The benchmarks were produced with code written for this dissertation which implemented the method described in Section~\ref{sec:mhd_exact}.  The availability of nonlinear solver is a significant contribution to the computational physics and space weather communities since it can be used for benchmarking or used or incorporated into a fluid solver for flux evaluations.  

Entirely new work was presented in Chapter~\ref{chp:cwm}.  A modification to the finite volume method can be used to produce the correct solutions to non-unique Riemann problems of ideal MHD equations.  The properties of the planar ideal MHD equations discussed in \citep{Falle:2001} were used to describe the appearance of compound wave structures in finite volume approximations.  The flux is modified near a large rotation ($\beta_T > 2.0$) so that the upstream and downstream states satisfy the jump conditions for a rotational discontinuity.  The method may be well suited for simulations in two- and three-dimensions because it does not track the rotational discontinuity.

The CWM method also gives true convergence for problems with initial conditions near those with a non-unique solution.  It is the first flux approximation for a dissipative finite volume scheme that does not exhibit pseudo-convergence.  The number of grid points required to obtain RMSEs on the order of $10^{-2}$ is reduced by nearly two orders of magnitude for both the near coplanar case containing a SCW and the case containing a FCW.  

The CWM method can be applied in simulations on a wide range of spatial scales, but it is best suited for large-scale simulations for two reasons: smoothing oscillations caused by over-shoots downstream of the Alfv{\'e}n wave is required for small scale simulations and the greatest reduction in $L^1$-errors are achieved at lower resolutions.    
  
The CWM method should be tested with other methods of approximating numerical fluxes in FVMs.  For Roe-type methods that use solutions to the linearized system of equations, the intermediate states can be approximated as linear combinations of the eigenvalues and eigenvectors of the Jacobian (Eq. 3.19, \citep{Ryu:1995a}).  The HLLD method is convenient to use with the CWM method because it gives the exact solution to an isolated rotational discontinuity \citep{Miyoshi:2005} and its intermediate states provide an initial guess that results in a high rate of convergence for the nonlinear solver if it is used with CWM.  If a nonlinear solver is used, more frequent calls may be required for problems in two- and three- dimensions.  In this case, reducing the number of iterations can decrease computational costs without a loss in accuracy of the final solution.  It is important to stress that the results of Chapter~\ref{chp:cwm} were obtained exclusively with the HLLD approximate Riemann in conjunction with CWM.  Although a nonlinear solver may potentially improve the accuracy of CWM, it is not required.  That is a unique property of CWM and another reason why, along with improved accuracy and the potential for simulations in higher dimension, its development is a substantial contribution to the computational physics and space weather communities.
 
The new results of Section~\ref{sec:riemann_mhd} and Chapter~\ref{chp:cwm} were bookended by the development of a multidimensional fluid solver capable of running in parallel on shared memory processors.  This code was developed to test the viability of using a GPU as the primary device for shared memory parallelism in place of the CPU.  The GPU was shown to outperform the CPU by two to three times.  Essential algorithms such as face coloring were explained for cell center FV with and without CT.  The code was verified with comparisons to well known results.  It was argued that the cost to performance ratio for a GPUs such as NVIDIAs GTX Titan is worth the investment as long as the reduction in available memory from the CPU is handled effectively.  This dissertation described and implemented operator fusion to reduce memory requirements and SoA data storage to increase performance on the GPU.  This fluid solver capable of shared memory parallelism and the accompanying description within this dissertation can be used as a blueprint or benchmark by anyone looking to incorporate GPUs to increase solver performance, making it a significant contributions to the computational physics and space weather communities. 

